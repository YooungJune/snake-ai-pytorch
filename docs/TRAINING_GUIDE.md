# 🧠 强化学习训练指南

## 为什么前几局分数不佳？

这是**完全正常的强化学习现象**，有以下几个原因：

### 1. **探索阶段 (Exploration Phase)**
- 前80局：AI 主要进行**随机探索**，学习游戏环境
- `epsilon = 80 - n_games`，前80局 epsilon 从80递减到0
- 随机探索时，AI 做出的决策不是最优的，分数必然较低
- **这是必要的！** 没有探索，AI 无法学习有效的策略

### 2. **梯度下降的波动性**
- 神经网络训练过程中，损失函数会波动
- 即使是同样的策略，也会因为随机初始化而有差异
- 这导致前几局分数不稳定

### 3. **经验回放缓冲池 (Experience Replay)**
- 前几局的经验数据较少
- `BATCH_SIZE = 1000`，需要积累足够的经验才能进行有效的批量训练
- 前期缓冲池太小，训练效果有限

### 4. **Q值初始化**
- 神经网络权重随机初始化
- Q值估计初期会很差
- 需要多次训练才能收敛到较好的值

## 正常的训练曲线示例

```
游戏局数    |  平均分数    |  说明
-----------|-------------|--------------------
1-50       |  2-5        |  大量随机探索，分数最低
51-100     |  5-15       |  开始学习，分数逐步提高
101-200    |  10-20      |  进入学习阶段，开始有明显策略
201-500    |  15-30      |  策略成熟，分数相对稳定
500+       |  25-40+     |  模型充分训练，表现最佳
```

## 为什么改进了 epsilon 衰减？

**原问题：** 
- 当继续训练时，`epsilon = max(0, 80 - 250) = 0`
- 第250局后完全停止探索，只用模型预测
- 但模型可能还不够好，导致分数下降

**新方案：**
```python
self.epsilon = max(0, 80 - (self.n_games % 200))
```
- 每200局重置一次探索周期
- 避免过度依赖不完美的模型
- 定期重新探索新的策略

## 优化建议

### 1. **继续训练至少500局**
- 前100局：模型学习基本策略
- 100-500局：模型不断优化
- 500+局：性能趋于稳定

### 2. **监控训练进度**
```powershell
# 快速评估当前模型
python play_game.py --games 50 --no-display
```
查看 **平均得分** 是否在上升趋势

### 3. **调整超参数（如果需要）**

在 `agent.py` 中修改：

```python
# 增加探索阶段长度（学习更慢但更全面）
self.epsilon = max(0, 150 - (self.n_games % 300))  # 原来是80

# 或调整学习率
LR = 0.01  # 原来是 0.005，更大的学习率更快收敛
```

### 4. **定期备份模型**
```powershell
# 保存当前最好的模型
Copy-Item model/model.pth model/model_best.pth
```

## 期望的改进时间表

| 时间点 | 预期表现 | 建议行动 |
|--------|---------|---------|
| 0-100局 | 分数2-10，波动大 | 继续训练，不要放弃 |
| 100-300局 | 分数8-20，逐步改善 | 监控趋势，确认在上升 |
| 300-500局 | 分数15-30，相对稳定 | 模型基本可用 |
| 500+局 | 分数20+，稳定性好 | 模型充分训练 |

## 诊断模型质量

### 分数仍不理想？检查以下几点：

1. **是否训练了足够局数？**
   ```powershell
   cat model/history_score.json
   # 查看 n_games 数值
   ```

2. **是否有明显上升趋势？**
   ```powershell
   python play_game.py --games 100 --no-display
   # 对比当前分数和 history_score.json 中的最高分
   ```

3. **模型是否在正常训练？**
   - 查看 agent.py 的输出
   - 应该看到 "Game X Score Y" 的持续增长

## 常见误区

❌ **误区1：** "第1局分数低说明模型坏了"
- ✓ 正确：这是正常的探索阶段

❌ **误区2：** "我要重新开始训练"
- ✓ 正确：继续训练现有模型，不要删除

❌ **误区3：** "分数波动说明有问题"
- ✓ 正确：训练过程中分数波动是正常的

## 总结

🎯 **关键点：**
1. 前期低分是**必然的**，这不是 bug
2. 需要**耐心训练**至少 500 局
3. 观察**整体趋势**，不要关注单局分数
4. 定期用 `play_game.py` 评估模型性能

💪 **坚持训练，效果会慢慢改善！**
